<html>
    <head>
        <link rel="stylesheet" href="style.css">
    </head>
    <body>
        <p id="page">296</p>
        <p>assumption, where there are slots for questions, answers, tables of contents, and
bibliographies, and a minimal amount of surrounding context. However, FAQs are much
            closer to free text than HTML pages, which constitute the focus of most text-mining
machine-learning systems</p>
        <p>&nbsp &nbsp &nbsp &nbsp The researchers who advocate machine-learning approaches to text mining often
state that the manual encoding of rules is tedious and labor intensive. Consequently,
machine-learning approaches are more promising, because they can learn the rules
automatically. This argument has definite merits, but does not explain the full picture. In
practice, all successful machine-learning approaches require a domain theory (Freitag,
1998), that must be encoded manually. Many machine- learning approaches also require
that input data be represented in a specific way, effectively taking knowledge representation for granted. Thus, the promise of automation is never completely f</p>
        <p>&nbsp &nbsp &nbsp &nbsp Many text-oriented machine-learning techniques (Charniak, 1997; Ng & Zelle, 1997)
are very powerful and promising. However, their main weakness is that they are created
with no specific task in mind and do not easily yield to customization for specific domaindependent problems. When this customization is feasible, it is effectively equivalent to
manual knowledge engineering required in approaches similar to FAQ Minder’s.</p>
        <p>&nbsp &nbsp &nbsp &nbsp Numerical approaches in information retrieval offer yet another alternative to
qualitative free-text mining. We presented one such approach called TextTiling (Hearst,
1997; Hearst & Plaunt, 1993). TextTiling was designed for large documents and large
sections, containing enough word data for variances between topics to be statistically
noticeable. This technique would probably not be effective in segmenting FAQ files or
similar documents, since questions are one or two sentences and answers typically no
more than 200 words.
        <p>&nbsp &nbsp &nbsp &nbsp Each approach presented in this chapter has its strengths and weaknesses. None
of them solves the problem of free-text data-mining completely. Qualitative approaches,
such as FAQ Minder’s, produce good results but require manual knowledge engineering.
Machine-learning methods can acquire complete data-mining models automatically but
require domain theories and strict data formats. Information retrieval approaches do not
require any knowledge engineering but cannot function without large text corpora.
Hence, we believe that hybrid text-mining models are one of the most promising research
directions in free-text data mining. A hybrid model is a model that requires a modest
amount of knowledge engineering in exchange for scalable performance and acceptable
results. The idea behind hybrid models is intuitively appealing: combine the relative
strengths of the available alternatives, while minimizing their relative weaknesses.</p>
            <h2 id="heading">ENDNOTES</h2>
        <p>1 &nbsp &nbsp &nbsp &nbsp We use the terms logical structure of documents and structural organization of
            information in documents interchangeably.</p>
        <p>2 &nbsp &nbsp &nbsp &nbsp Since the approach presented in this chapter complements the existing approaches,
it cannot be easily compared to them, because it is based on different assumptions.
A comparison, by definition, is possible only among competing approaches.
</p>
        <p id="page">297</p>
        <h2 id="heading">ACKNOWLEDGMENTS</h2>
        <p>&nbsp &nbsp &nbsp &nbsp We would like to thank Kristian Hammond for his countless contributions to the
FAQ Finder project. Kris was the founder of the FAQ Finder project, and deserves credit
for putting together the original FAQ Finder team at the University of Chicago’s
Intelligent Information Laboratory. We would like to express our gratitude to Jay Budzik
who contributed to the development of the FAQ Minder system. Steve Lytinen and
Noriko Tomuro offered us many helpful comments.</p>
<h2 id="heading">REFERENCES</h2>
        <ul><p>Allen, J. (1987). <i>Natural language understanding.</i> Menlo Park, CA: Benjamin/Cummings
Publishing Company.</p>
            <p>Bookstein, A. & Swanson, D. R. (1974). Probabilistic models for automatic indexing.
                <i>Journal of the American Society for Information Science, 25(5), 312-318.</i></p>
            <p>Brill, E. & Mooney, R. J. (1997). An overview of empirical natural language processing.
                <i>AI Magazine, 18(4), 13-24.</i></p>
            <p>Burke, R., Hammond, K., & Cooper, E. (1996). Knowledge-based information retrieval
from semi-structured text.<i> Proceedings of the AAAI Workshop on Internet-Based
                Information Systems. </i>Madison, WI: AAAI Press, pp. 18-24.</p>
            <p>Burke, R. D., Hammond, K. J., Kulyukin, V., Lytinen, S. L., Tomuro, N., & Schoenberg, S.
(1997). Question answering from frequently asked question files: Experiences with
                the FAQ Finder System. <i>AI Magazine, 18(2), 57-66.</i></p>
            <p>Burke, R. D., Hammond, K. J., & Young, B. C. (1996). Knowledge-based navigation of
                complex information spaces. <i>Proceedings of the American Association for Artificial Intelligence Conferece</i></p>
            <p>Cardie, C. (1997). Empirical Methods in Information Extraction.<i> AI Magazine, 18(4), 65-
                79.</i></p>
            <p>Charniak, E. (1997). Statistical techniques for natural language parsing.<i> AI Magazine,
                18(4), 33-43.</i></p>
            <p>Clarke, C., Cormack, G. V., & Lynam T. R. (2001-). Exploiting redundancy in question
answering. <i>Proceedings of the Special Interest Group in Information Retrieval
                (ACM SIGIR) Conference.</i> New Orleans, USA, ACM Press, pp. 358-365.</p>
            <p>Daniels, J. & Rissland, E. (1995). A case-based approach to intelligent information
retrieval. <i>Proceedings of the Special Interest Group in Information Retrieval
                (ACM SIGIR) Conference, Seattle,</i> ACM Press, pp. 317-324.</p>
            <p>Frakes, W. & Baeza-Yates, R. (Eds.). (1992). <i>Information retrieval: Data structures and
                algorithms.</i> Upper Saddle River, NJ: Prentice Hall.</p>
            <p>Freitag, D. (1998). Information extraction from HTML: Application of a general machine
learning approach. <i>Proceedings of the 15th Conference on Artificial Intelligence
                (AAAI-98).</i> Menlo Park, CA: AAAI Press, pp. 517-523.</p>
            <p>Glasgow, B., Mandell, A., Binney, D., Ghemri, L., & Fisher, D. (1997). MITA: An
information-extraction approach to analysis of free-form text in life insurance
applications. <i>Proceedings of the Ninth Conference on Innovative Applications of
                Artificial Intelligence.</i> Menlo Park, CA: AAAI Press, pp. 213-219.</p>
            <p id="page">298</p>
            <p>Hammer, H., Garcia-Molina, J., Cho, R., Aranha, A., & Crespo. V. (1997). Extracting
semistructured information from the Web. <i>Proceedings of the Workshop on
                Management of Semistructured Data (PODS/SIGMOD’97),</i> Tucson, Arizona.</p>
            <p>Hearst, M. (1997). TextTiling: Segmenting text into multi-paragraph subtopic passages.
                <i>Computational Linguistics, 23(1), 33-64.</i></p>
            <p>Hearst, M.A. & Plaunt C. (1993). Subtopic structuring for full-length document access.
<i>Proceedings of the Special Interest Group in Information Retrieval (ACM SIGIR)
    Conference.</i> Pittsburgh, PA, pp. 59-68.</p>
            <p>Hopcroft, J. E. & Ullman, J. D. (1979). <i>Introduction to automata theory, languages, and
                computation. </i>Reading, MA: AddisonWesley.</p>
            <p>Hsu, C. N. & Chang, C. C. (1999). Finite-state transducers for semi-structured text mining.
<i>Proceedings of International Joint Conference on Artificial Intelligence (IJCAI)
    Workshop on Text Mining. </i>IJCAI Press, pp. 76-82.</p>
            <p>Jacquemin, C. & Bush, C. (2000). Combining lexical and formatting cues for named entity
acquisition from the Web. <i>Proceedings of the Joint SIGDAT Conference on
                Empirical Methods in Natural Language Processing and Very Large Corpora.</i>
Hong Kong University of Science and Technology, ACM Press, pp. 189-193.</p>
            <p>Kulyukin, V. (1998a). FAQ Finder: A gateway to newsgroups’ expertise.<i> Proceedings of
                the 40th Conference of Lisp Users, Association of Lisp Users, pp. 19-26.</i></p>
            <p>Kulyukin, V. (1998b). <i>Question-driven information retrieval systems.</i> Unpublished
doctoral dissertation, The University of Chicago, Chicago, IL.</p>
            <p>Kulyukin, V., Hammond, K., & Burke, R. (1996). Automated analysis of structured online
documents. <i>Proceedings of the Workshop on Internet-Based Information Systems,
                Portland, Oregon.</i> Menlo Park, CA: AAAI Press, pp. 23-29.</p>
            <p>Kushmerick, N., Weld, D., & Doorenbos, D. (1997). Wrapper induction for information
extraction.<i> Proceedings of the International Joint Conference on Artificial
                Intelligence (IJCAI), Providence, Rhode Island. IJCAI Press, pp. 25-34.</i></p>
            <p>Miller, G. A. (1995). WordNet®: A lexical database for English.<i> Communications of the
                ACM, 38(11), 39-41.</i></p>
            <p>Mitchell, T. M. (1997). <i>Machine learning.</i> New York: McGraw-Hill.</p>
            <p>Moore, D. S. & McCabe, G. P. (1993). <i>Introduction to the practice of statistics</i> (2nd ed.).
New York: W.H. Freeman and Company.</p>
            <p>MUC-3. (1991). <i>Proceedings of the Third Message-Understanding Conference </i>(MUC3). San Francisco, CA: Morgan Kaufmann.</p>
            <p>MUC-4. (1992).<i> Proceedings of the Fourth Message-Understanding Conference </i>(MUC4). San Francisco, CA: Morgan Kaufmann.</p>
            <p>Ng, H. T. & Zelle, J. (1997). Corpus-based approaches to semantic interpretation in NLP.
                <i>AI Magazine,</i> 18(4), 45-64.</p>
            <p>Norvig, P. (1992). <i>Paradigms of artificial intelligence programming: Case studies in
                common lisp. </i>San Mateo, CA: Morgan Kaufmann.</p>
            <p>Palmer, D. & Hearst, M. (1994). Adaptive sentence boundary disambiguation. <i>Proceedings of the 4th Conference on Applied Natural Language Processing.</i> Stuttgart,
Germany, ACM Press, pp. 78-83.</p>
            <p>Salton, G. & McGill, M. (1983).<i> Introduction to modern information. retrieval. </i>New York:
McGraw-Hill.</p>
            <p id="page">299</p>
            <p>Srinivasan, P. (1992). Thesaurus construction. In W. Frakes & R. Baeza-Yates (eds.),
                <i>Information retrieval: Data structures and algorithms (pp. 161-218).</i> Upper Saddle
River, NJ: Prentice Hall.</p>
            <p>Voorhees, E. & Harman, D. (Eds.). (2000).<i> Proceedings of the Ninth Text Retrieval
                Conference</i> (TREC),</i> ACM Press.</p>
    <p>Voorhees, E. & Tice, D. (2000). Building a question answering test collection. <i>Proceedings of the Special Interest Group in Information Retrieval </i>(ACM SIGIR) Conference. Athens, Greece, ACM Press,pp.200-20-7.</p>
             </ul>
            <h2 id="heading">APPENDIX</h2>
            <p> &nbsp &nbsp &nbsp &nbsp Spreading activation is used to account for lexical variation between the clients’
questions and the FAQ answers. Spreading activation is based on WordNet, which
consists of four subnets organized by the four parts of speech. Each subnet has its own
relations: for example, nouns have antonymy, the isa relation, and three part-of relations.
WordNet’s basic unit is a synset, which contains words and phrases interchangeable in
a context, e.g., “computer” and “data processor.” Spreading activation is used to account for lexical variation between the clients’
questions and the FAQ answers. Spreading activation is based on WordNet, which
consists of four subnets organized by the four parts of speech. Each subnet has its own
relations: for example, nouns have antonymy, the isa relation, and three part-of relations.
WordNet’s basic unit is a synset, which contains words and phrases interchangeable in
a context, e.g., “computer” and “data processor.”</p>
            <p> &nbsp &nbsp &nbsp &nbsp The activation procedure is depth-constrained. It takes a term and a depth integer
specifying how many links away from thr.e term the activation is to spread. Each term found
during the spread is annotated with its part of speech and the depth at which it was found.
Thus, “device12” means that “device” is a noun found at depth 2. The origin term’s depth
is 0. If a word is found at several depths, only the smallest one is kept. Activation is spread
only from terms found in the questions. Since questions in FAQs are shorter than
answers, the number of non-relevant terms found during the spread is much smaller that
it would be if the activation was spread from every nonstoplisted term in every answer.</p>
            <p> &nbsp &nbsp &nbsp &nbsp The weight of a term combines its semantic and statistical properties. The semantic
properties of a term constitute its intrinsic value. The statistical properties reflect its value
in the collection of textual units. The semantic weight of a term <img src="Screenshot (37).png" >,is given by</p>
            <center>
                <img src="Screenshot (38).png">
            </center>
<p>where <i>Poly(t<sub>i</sub>)</i> gives the term’s polysemy, <i>d(t<sub>i</sub>)</i> gives the depth at which <i>t<sub>i</sub></i>was found, <i>W<sub>pos</sub></i>
assigns a constant weight to each part of speech, i.e., 1 to nouns, .75 to verbs, and .5 to
    adjectives and adverbs, and the rate of decay, r < 1, indicates how much<i>t<sub>i</sub></i>’s weight decreases
with depth.</p>
            <p> &nbsp &nbsp &nbsp &nbsp The statistical weight of a term combines several approaches. Let<i>K</i>  be a collection
of <i>D</i> documents. Let <i>d<sub>j</sub></i> be a document in <i>K</i>. If<img src="Screenshot (39).png">denotes the frequency of occurrence of <i> t<sub>i</sub></i>in <i>d<sub>j</sub></i>
                , then <img src="Screenshot (40).png">denotes the number of occurrences of<i> t<sub>i</sub></i>in <i>K</i>. Let <i>N<sub>i</sub></i>
be the number of documents containing at least one occurrence of t<sub>i</sub>.N<sub>i</sub> depends on the</p>
         <p id="page">300</p>
        <p>distribution of <img src="Screenshot (44).png">among the documents of <i>K</i>. Let <img src="Screenshot (45).png"> be the random variable that assumes
            the values of <i>N<sub>i</sub></i> and let <img src="Screenshot (46).png">be its expected value, assuming that each occurrence
            of <i>t<sub>i</sub></i>can fall into any of the <i>D</i> documents with equal probability.</p>
        <p>&nbsp &nbsp &nbsp &nbsp The first statistical weight metric is the <i>inverse document frequency </i>(Salton &
            McGill, 1983). The inverse document frequency <i>(IDF) </i> of<i> t<sub>i</sub></i> in <i>K,W<sub>idf</sub>(t<sub>i</sub>K)</i>,is given by 1+log(<i>D/N</i>).The <i>tfidf</i> weight of <i>t<sub>i</sub></i>
            in <i>d<sub>j</sub>,W<sub>tfidf</sub>(t<sub>i</sub>,d<sub>j</sub>),</i> is given by <i>f(t<sub>i</sub>,d<sub>j</sub>)W<sub>idf</sub>(t<sub>i</sub>,K).</i></p>
        <p>The second statistical weight metric is condensation clustering (Kulyukin, 1998b). A
sequence of textual units proceeds from topic to topic. Terms pertinent to a topic exhibit a
non-random tendency to condense in the units that cover the topic. One refers to such terms
            as <b>content-bearing.</b> Terms that do not bear content appear to be distributed randomly over
the units. The condensation clustering (CC) weight of <i>t<sub>i</sub>,W<sub>cc</sub>(t<sub>i</sub>K),</i> is a ratio of the actual
number of documents containing at least one occurrence of <i>t<sub>i</sub></i>over the expected number of such documents and is given by <img src="Screenshot (47).png" where <i>A</i>,where A is a constant.
The following lemma shows how to compute the expectation of <i>N<sub>i</sub></i>.</p>
        <p><b>Lemma 1:</b> Let Ti be the total number of occurrences of t<sub>i</sub> in K. Then <img src="Screensho>t (42).png">
            , where <center><img src="Screenshot (43).png"></center> </p>
        <p><b>Proof:</b> For each <i>d<sub>j</sub></i>,put <i>n<sub>j</sub></i>=1 if <i>f(t<sub>i</sub>,d<sub>j</sub>)>0</i>and <i>n<sub>j</sub></i>=0,otherwise.This random
variable assumes the values of 1 and 0 with corresponding probabilities of <i>p<sub>i</sub></i> and 1-<i>p<sub>i</sub></i>.Hence,<img src="Screenshot (49).png">Since <img src="Screenshot (50).png"</p>
            <p>&nbsp &nbsp &nbsp &nbsp The CC weight of <i>t<sub>i</sub></i> captures its importance in <i>K</i>. To account for <i>t<sub>i</sub></i> ’s importance
in <i>d<sub>j</sub></i> , its CC weight is multiplied by its frequency in <i>d<sub>j</sub></i>. Thus, we obtain another statistical
                weight metric <i>W<sub>tfcc</sub>(t<sub>i</sub> , d<sub>j</sub> , K)= f(t<sub>i</sub> , d<sub>j</sub>)W<sub>cc</sub>(t<sub>i</sub>,K)</i>.The following lemma captures the relationship between <i>IDF</i> and <i>CC.</i></p>
<p><b>Lemma 2:</b><img src="Screenshot (51).png"></p>
    <p><b>Proof:</b>By lemma 1 and the definition of<img src="Screenshot (52).png">But, </p>

     <p>&nbsp &nbsp &nbsp &nbsp<img src="Screenshot (53).png"></p>  
        
        
    
        
        
        
        
    </body>
</html>